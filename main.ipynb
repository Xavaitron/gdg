{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 1",
   "id": "2e3956f043a942e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:25:35.507119Z",
     "start_time": "2024-12-15T03:25:34.961746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf"
   ],
   "id": "c3cd9515997032c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-15T03:26:32.206791Z",
     "start_time": "2024-12-15T03:25:37.158824Z"
    }
   },
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Fetch Nifty50 data from NSE\n",
    "# ---------------------------------------------------------\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "    \"Referer\": \"https://www.nseindia.com/\"\n",
    "})\n",
    "session.get(\"https://www.nseindia.com\")\n",
    "\n",
    "nifty50_url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050\"\n",
    "response = session.get(nifty50_url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "symbols = [item['symbol'] for item in data['data']]\n",
    "\n",
    "if \"NIFTY 50\" in symbols:\n",
    "    symbols.remove(\"NIFTY 50\")\n",
    "\n",
    "nse_details = {}\n",
    "for item in data['data']:\n",
    "    sym = item['symbol']\n",
    "    nse_details[sym] = {\n",
    "        \"LTP\": item.get('lastPrice'),\n",
    "        \"Volume\": item.get('totalTradedVolume'),\n",
    "        \"%Change\": item.get('pChange'),\n",
    "        \"52W_High\": item.get('yearHigh'),\n",
    "        \"52W_Low\": item.get('yearLow'),\n",
    "        \"Day_High\": item.get('dayHigh'),\n",
    "        \"Day_Low\": item.get('dayLow')\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 2: Fetch PE, EPS, Market Cap from yfinance's stock.info\n",
    "# ---------------------------------------------------------\n",
    "info_data = {}\n",
    "for sym in symbols:\n",
    "    yahoo_symbol = sym + \".NS\"\n",
    "    try:\n",
    "        stock = yf.Ticker(yahoo_symbol)\n",
    "        info = stock.info\n",
    "    except:\n",
    "        info = {}\n",
    "    pe = info.get('trailingPE', np.nan)\n",
    "    eps = info.get('trailingEps', np.nan)\n",
    "    market_cap = info.get('marketCap', np.nan)\n",
    "\n",
    "    info_data[sym] = {\n",
    "        \"PE\": pe,\n",
    "        \"EPS\": eps,\n",
    "        \"Market_Cap\": market_cap\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 3: Compute Returns from Yahoo Finance (6M, 1Y, 5Y)\n",
    "# ---------------------------------------------------------\n",
    "def get_returns(symbol):\n",
    "    yahoo_symbol = symbol + \".NS\"\n",
    "    end = datetime.now()\n",
    "    start_5y = end - timedelta(days=5 * 365)\n",
    "    try:\n",
    "        df_yf = yf.download(yahoo_symbol, start=start_5y, end=end, progress=False)\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "    if df_yf.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    current_price = df_yf['Adj Close'].iloc[-1].item() if hasattr(df_yf['Adj Close'].iloc[-1], 'item') else \\\n",
    "    df_yf['Adj Close'].iloc[-1]\n",
    "\n",
    "    # 6-month return\n",
    "    start_6m = end - timedelta(days=182)\n",
    "    df_6m = df_yf[df_yf.index >= start_6m]\n",
    "    ret_6m = None\n",
    "    if not df_6m.empty:\n",
    "        old_6m = df_6m['Adj Close'].iloc[0].item() if hasattr(df_6m['Adj Close'].iloc[0], 'item') else \\\n",
    "        df_6m['Adj Close'].iloc[0]\n",
    "        ret_6m = ((current_price - old_6m) / old_6m) * 100\n",
    "\n",
    "    # 1-year return\n",
    "    start_1y = end - timedelta(days=365)\n",
    "    df_1y = df_yf[df_yf.index >= start_1y]\n",
    "    ret_1y = None\n",
    "    if not df_1y.empty:\n",
    "        old_1y = df_1y['Adj Close'].iloc[0].item() if hasattr(df_1y['Adj Close'].iloc[0], 'item') else \\\n",
    "        df_1y['Adj Close'].iloc[0]\n",
    "        ret_1y = ((current_price - old_1y) / old_1y) * 100\n",
    "\n",
    "    # 5-year return\n",
    "    old_5y = df_yf['Adj Close'].iloc[0].item() if hasattr(df_yf['Adj Close'].iloc[0], 'item') else \\\n",
    "    df_yf['Adj Close'].iloc[0]\n",
    "    ret_5y = ((current_price - old_5y) / old_5y) * 100\n",
    "\n",
    "    return ret_6m, ret_1y, ret_5y\n",
    "\n",
    "\n",
    "returns_data = {}\n",
    "for sym in symbols:\n",
    "    returns_data[sym] = get_returns(sym)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 4: Combine all data into a DataFrame\n",
    "# ---------------------------------------------------------\n",
    "all_rows = []\n",
    "for sym in symbols:\n",
    "    rets = returns_data[sym]\n",
    "\n",
    "    row = {\n",
    "        \"Symbol\": sym,\n",
    "        \"LTP\": nse_details[sym].get(\"LTP\"),\n",
    "        \"Volume\": nse_details[sym].get(\"Volume\"),\n",
    "        \"%Change\": nse_details[sym].get(\"%Change\"),\n",
    "        \"PE\": info_data[sym].get(\"PE\"),\n",
    "        \"EPS\": info_data[sym].get(\"EPS\"),\n",
    "        \"Market_Cap\": info_data[sym].get(\"Market_Cap\"),\n",
    "        \"52W_High\": nse_details[sym].get(\"52W_High\"),\n",
    "        \"52W_Low\": nse_details[sym].get(\"52W_Low\"),\n",
    "        \"Upper_Circuit\": nse_details[sym].get(\"Day_High\"),\n",
    "        \"Lower_Circuit\": nse_details[sym].get(\"Day_Low\"),\n",
    "        \"6M_Return%\": rets[0] if rets else np.nan,\n",
    "        \"1Y_Return%\": rets[1] if rets else np.nan,\n",
    "        \"5Y_Return%\": rets[2] if rets else np.nan\n",
    "    }\n",
    "\n",
    "    all_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Symbol       LTP    Volume  %Change         PE     EPS      Market_Cap  \\\n",
      "0  BHARTIARTL   1682.00  12900707     4.44  81.283226   20.69  10068587184128   \n",
      "1         ITC    471.00  31753858     2.26  28.658537   16.40   5880076042240   \n",
      "2   KOTAKBANK   1804.90   3893531     2.05  16.474909  109.60   3589921046528   \n",
      "3  HINDUNILVR   2391.25   2260902     1.97  54.643350   43.74   5615755198464   \n",
      "4  ULTRACEMCO  12082.35    408880     1.90  53.190865  227.18   3485226500096   \n",
      "\n",
      "   52W_High  52W_Low  Upper_Circuit  Lower_Circuit  6M_Return%  1Y_Return%  \\\n",
      "0    1779.0   960.00        1685.00        1606.80   18.396895   70.777290   \n",
      "1     528.5   399.35         474.40         451.65    9.620991    7.464088   \n",
      "2    1942.0  1543.85        1809.00        1748.05    5.131385   -2.128963   \n",
      "3    3035.0  2172.05        2394.55        2333.45   -3.137340   -4.093450   \n",
      "4   12138.0  9250.00       12118.50       11730.00    9.321947   21.917101   \n",
      "\n",
      "   5Y_Return%  \n",
      "0  296.572930  \n",
      "1  140.538335  \n",
      "2    5.708602  \n",
      "3   31.882061  \n",
      "4  200.519598  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 2",
   "id": "844e778c12e0d413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:36:16.488009Z",
     "start_time": "2024-12-15T03:36:12.950737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, t\n",
    "from math import sqrt\n",
    "\n",
    "# Fetch historical data for a chosen stock, e.g., Apple (AAPL)\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Compute daily returns\n",
    "df['Daily_Return'] = df['Adj Close'].pct_change()\n",
    "df = df.dropna(subset=['Daily_Return'])\n",
    "\n",
    "# Basic statistics\n",
    "mean_return = df['Daily_Return'].mean()\n",
    "std_return = df['Daily_Return'].std()\n",
    "n = len(df['Daily_Return'])\n",
    "\n",
    "print(\"Statistics:\")\n",
    "print(f\"Mean Daily Return: {mean_return}\")\n",
    "print(f\"Std Dev Daily Return: {std_return}\")\n",
    "print(f\"Sample Size (n): {n}\")\n",
    "\n",
    "# Z-scores for daily returns\n",
    "df['Daily_Return_Z'] = (df['Daily_Return'] - mean_return) / std_return\n",
    "\n",
    "# For T-scores, we typically use the sample mean and sample std with a t-distribution.\n",
    "# Confidence Interval for mean daily return (95% CI)\n",
    "alpha = 0.05\n",
    "df_degrees = n - 1\n",
    "t_crit = t.ppf(1 - alpha/2, df_degrees)\n",
    "margin_of_error = t_crit * std_return / sqrt(n)\n",
    "ci_lower = mean_return - margin_of_error\n",
    "ci_upper = mean_return + margin_of_error\n",
    "print(f\"95% Confidence Interval for Mean Daily Return (t-based): [{ci_lower}, {ci_upper}]\")\n",
    "\n",
    "# If we assume population std known (hypothetical), we can use Z-based CI:\n",
    "z_crit = norm.ppf(1 - alpha/2)\n",
    "z_margin_of_error = z_crit * std_return / sqrt(n)\n",
    "z_ci_lower = mean_return - z_margin_of_error\n",
    "z_ci_upper = mean_return + z_margin_of_error\n",
    "print(f\"95% CI (z-based): [{z_ci_lower}, {z_ci_upper}]\")\n",
    "\n",
    "# Plot Probability Distributions\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Distribution of Daily Volume\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Volume'], kde=True, stat=\"density\")\n",
    "plt.title(f\"Distribution of Daily Volume for {ticker}\")\n",
    "plt.xlabel(\"Volume\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Daily Close Price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Adj Close'], kde=True, stat=\"density\")\n",
    "plt.title(f\"Distribution of Daily Close Price for {ticker}\")\n",
    "plt.xlabel(\"Adjusted Close Price\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Daily Returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Daily_Return'], kde=True, stat=\"density\")\n",
    "plt.title(f\"Distribution of Daily Returns for {ticker}\")\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Additionally, overlay a fitted normal PDF on daily returns\n",
    "mean_dr = mean_return\n",
    "std_dr = std_return\n",
    "x_values = np.linspace(df['Daily_Return'].min(), df['Daily_Return'].max(), 1000)\n",
    "pdf = norm.pdf(x_values, mean_dr, std_dr)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Daily_Return'], kde=False, stat=\"density\", label='Data')\n",
    "plt.plot(x_values, pdf, 'r', label='Fitted Normal PDF')\n",
    "plt.title(f\"Daily Returns Distribution with Normal Fit - {ticker}\")\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "d8d0c80052c07b06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['Daily_Return']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20072\\776185241.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0myf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mticker\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstart_date\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mend_date\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;31m# Compute daily returns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Daily_Return'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Adj Close'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpct_change\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Daily_Return'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# Basic statistics\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[0mmean_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Daily_Return'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\gdg\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001B[0m\n\u001B[0;32m   6666\u001B[0m             \u001B[0max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6667\u001B[0m             \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0max\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6668\u001B[0m             \u001B[0mcheck\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindices\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6669\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcheck\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6670\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcheck\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6671\u001B[0m             \u001B[0magg_obj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0magg_axis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6673\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mthresh\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_default\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ['Daily_Return']"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bonus",
   "id": "8aad202222eaf807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:40:34.803987Z",
     "start_time": "2024-12-15T03:40:33.922138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "# Choose any two stocks: e.g., Apple (AAPL), Microsoft (MSFT)\n",
    "# Adjust the date range as needed. For demonstration, we take data from 2023-01-01 to today.\n",
    "stock_symbols = [\"AAPL\", \"MSFT\"]\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2024-01-01\"  # Adjust if future date is unrealistic, or use str(datetime.today().date())\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "data = yf.download(stock_symbols, start=start_date, end=end_date)['Adj Close'].dropna()\n",
    "\n",
    "# If multi-column: data is a DataFrame with a MultiIndex (Stock symbol, fields)\n",
    "# If single column, just handle accordingly.\n",
    "# Let's assume we have a separate series for each stock:\n",
    "returns_data = {}\n",
    "for symbol in stock_symbols:\n",
    "    # Compute daily returns\n",
    "    stock_prices = data[symbol].dropna()\n",
    "    stock_returns = stock_prices.pct_change().dropna()\n",
    "    returns_data[symbol] = stock_returns\n",
    "\n",
    "    # Perform ADF test\n",
    "    adf_result = adfuller(stock_returns, autolag='AIC')\n",
    "    adf_stat, adf_pvalue = adf_result[0], adf_result[1]\n",
    "\n",
    "    # Perform KPSS test\n",
    "    # KPSS requires a trend='c' or 'ct', commonly 'c' is used for level stationarity\n",
    "    kpss_result = kpss(stock_returns, regression='c')\n",
    "    kpss_stat, kpss_pvalue = kpss_result[0], kpss_result[1]\n",
    "\n",
    "    print(f\"Results for {symbol}:\")\n",
    "    print(\"ADF Test:\")\n",
    "    print(f\"  Test Statistic: {adf_stat}\")\n",
    "    print(f\"  p-value: {adf_pvalue}\")\n",
    "    if adf_pvalue < 0.05:\n",
    "        print(\"  The series is likely stationary based on ADF.\")\n",
    "    else:\n",
    "        print(\"  The series is likely non-stationary based on ADF.\")\n",
    "\n",
    "    print(\"KPSS Test:\")\n",
    "    print(f\"  Test Statistic: {kpss_stat}\")\n",
    "    print(f\"  p-value: {kpss_pvalue}\")\n",
    "    if kpss_pvalue < 0.05:\n",
    "        print(\"  The series is likely non-stationary based on KPSS.\")\n",
    "    else:\n",
    "        print(\"  The series is likely stationary based on KPSS.\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Interpretation:\n",
    "# ADF null: series is non-stationary; reject null if p < 0.05 => stationary\n",
    "# KPSS null: series is stationary; reject null if p < 0.05 => non-stationary\n",
    "# If ADF says stationary and KPSS says stationary, then the series is likely stationary.\n",
    "# If ADF says non-stationary and KPSS says non-stationary, it suggests the series is likely non-stationary.\n",
    "# Contradicting results might require further analysis.\n"
   ],
   "id": "9066017a0f1692d6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AAPL:\n",
      "ADF Test:\n",
      "  Test Statistic: -14.86434114215758\n",
      "  p-value: 1.700428345558108e-27\n",
      "  The series is likely stationary based on ADF.\n",
      "KPSS Test:\n",
      "  Test Statistic: 0.36915915418316775\n",
      "  p-value: 0.09044864043828976\n",
      "  The series is likely stationary based on KPSS.\n",
      "--------------------------------------------------\n",
      "Results for MSFT:\n",
      "ADF Test:\n",
      "  Test Statistic: -13.491226513539486\n",
      "  p-value: 3.103435404614185e-25\n",
      "  The series is likely stationary based on ADF.\n",
      "KPSS Test:\n",
      "  Test Statistic: 0.10853812271998156\n",
      "  p-value: 0.1\n",
      "  The series is likely stationary based on KPSS.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ironp\\AppData\\Local\\Temp\\ipykernel_20072\\2356878890.py:28: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  kpss_result = kpss(stock_returns, regression='c')\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The warning from the KPSS test indicates that the test statistic is outside the precomputed lookup table range for p-values. This often means the p-value is just at the boundary of the test’s internal tables. However, since the reported p-values are above 0.05, the conclusion remains that we cannot reject stationarity.\n",
    "\n",
    "Conclusion:\n",
    "Both the ADF and KPSS tests suggest that the daily returns of AAPL and MSFT over the given 2023–2024 period are stationary time series."
   ],
   "id": "f3ddff9906c772e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
